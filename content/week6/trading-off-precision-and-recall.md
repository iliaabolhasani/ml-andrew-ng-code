---
title: "متوازن کردن Precision  و Recall"
date: 2020-10-19T21:27:10+03:30
draft: false
weight: 100
---

ممکن است ما نیاز به یک پیش بینی مطمئن از دو کلاس به وسیله رگرسیون لجستیک داشته باشیم. یک راه این است که آستانه را افزایش دهیم:

- پیش بینی 1 اگر: $h_{\theta }\left ( x \right ) \geq 0.7$
- پیش بینی 0 اگر: $h_{\theta }\left ( x \right ) < 0.7$

بدین ترتیب تنها درصورتی که بیمار 70% شانس بیماری داشته باشد، سرطان را پیش بینی می‌کنیم.

اکنون ما precision زیادتر و recall کمتر خواهیم داشت(با توجه به تعاریف در بخش قبل).

در یک مثال متفاوت، میتوان آستانه را کمتر کرد:

- پیش بینی 1 اگر: $h_{\theta }\left ( x \right ) \geq 0.3$
- پیش بینی 0 اگر: $h_{\theta }\left ( x \right ) < 0.3$

که با این روش، پیش بینی **مطمئن‌تری** خواهیم داشت. که منجر به recall زیادتر و precision کمتر خواهد شد.

هرچه آستانه زیادتر باشد، precision زیادتر و recall کمتر خواهد بود.

هرچه آستانه کمتر باشد، recall زیادتر و precision کمتر خواهد بود.

برای تبدیل این دو استاندارد به یک عدد واحد می‌توانیم از **مقدار F** استفاده کنیم.

یک راه استفاده از **میانگین** است:
$\frac{P + R }{2}$

اما این راه حل مناسبی نیست. اگر تمامی مقادیر y را با 0 پیش بینی کنیم(y = 0) با وجود recall = 0، میانگین بالا خواهد رفت.

اگر تمامی نمونه‌ها را با y=1 پیش بینی کنیم، recall بسیار بالا با وجود precision = 0، میانگین را بالا خواهد برد.

راه حل بهتر محاسبه F Score خواهد بود(یا F1 Score):

$$
F Score = 2\frac{PR}{P + R}
$$

برای زیاد بودن مقدار F، هردو مقدار precision و recall باید زیاد باشند.

ما می‌خواهیم Precision و Recall را روی **مجموعه Cross validaion**  آموزش دهیم تا مجموعه آزمون دچار بایاس نشود.