---
title: "گرادیان کاهشی قسمت اول"
date: 2020-09-09T16:31:43+04:30
draft: false
weight : 80
---

### گرادیان کاهشی 

<span class="top-dict" data-tipso="gradient descent">گرادیان کاهشی</span>
 را برای مینیمم کردن 
<span class="top-dict" data-tipso="cost function">تابع هزینه</span>
$J$
استفاده می‌کنیم.
اما این الگوریتم تنها فقط در رگرسیون خطی کاربرد
ندارد، بلکه در سایر قسمت های حوزه یادگیری ماشین
نیز استفاده می‌شود.

![دوره یادگیری ماشین دانشگاه استنفورد به فارسی](../images/image30.png?width=15pc)

مراحل کار به این شکل است:

با حدس های اولیه برای دو پارامتر $\theta_0$ و $\theta_1$ شروع می‌کنیم، 
مثلا مقدار هر دو را در ابتدا $0$ تعیین می‌کنیم.

و سپس مقادیر $\theta_0$ و $\theta_1$ را به صورت جزئی
تغییر می‌دهیم تا تابع $J$ کاهش یابد، تا زمانی که به 
مینیمم کلی یا محلی برسیم.

![دوره یادگیری ماشین دانشگاه استنفورد به فارسی](../images/image32.png?width=25pc)

برای درک بهتر فرض کنید موتور سواری هستید بر روی
سطح شکل زیر و می‌خواهید به پایین ترین نقطه این
سطح برسید!

که بسته به مقادیر پارامتر ها سفر خود را از یک نقطه
بر روی این سطح شروع می‌کنید.

![دوره یادگیری ماشین دانشگاه استنفورد به فارسی](../images/image33.png?width=25pc)

شما در همه جهات می‌چرخید و اطرافتان را نگاه
می‌کنید و سپس سعی می‌کنید مقدار کمی به پایین
در یک جهت بروید و در سریع ترین زمان به پایین برسید.
بنابراین به کدام جهت باید بروید ؟!

اگر از بالاترین نقطه شکل زیر حرکت کنید به این نقطه
نهایی در کف سطح می‌رسید.

![دوره یادگیری ماشین دانشگاه استنفورد به فارسی](../images/image34.png?width=25pc)

اما اگر نقطه شروع را کمی از سمت راست شروع کرده
بودید مسیرتان به این شکل می‌شد.

**که این ویژگی گرادیان کاهشی است!**

![دوره یادگیری ماشین دانشگاه استنفورد به فارسی](../images/image35.png?width=25pc)

و اما این تعریف ریاضی الگوریتم گرادیان کاهشی
است:

![دوره یادگیری ماشین دانشگاه استنفورد به فارسی](../images/image36.png?width=30pc)

قرار است به صورت مکرر این کار را ادامه بدهیم تا
به نقطه مینیمم برسیم!، 
اما اجازه دهید با مثال موتور قضیه را باز کنیم!


اینجا $\alpha$ / آلفا یا همان 
**<span class="top-dict" data-tipso="learning rate">نرخ یادگیری</span>**
شبیه به گاز موتور ما است که تعیین می‌کند میزان بزرگی حرکت ما به 
پایین چه قدر باشد.

عبارت مشتق $\frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1) $ نیز برای ما شبیه به فرمان موتور است که تعیین کننده جهت حرکت خواهد بود.

اما نکته ی دیگری نیز در گرادیان کاهشی وجود دارد
تغییر مقدار $\theta_0$ و $\theta_1$ در هر بار در فرمول باید
به صورت  پیوسته انجام بشود!، 
یعنی ابتدا مقادیر حساب شود و سپس به مقادیر بعد
از انجام محاسبه تغییر کند:

![دوره یادگیری ماشین دانشگاه استنفورد به فارسی](../images/image20.jpg?width=38pc)

اما به نظر شما کدام درست است ؟!

{{%expand "برای پاسخ کلیک کن" %}}
جواب درست شکل سمت چپ است، زیرا دو پارامتر هم زمان و پشت سر هم مقادیرشان تغییر می‌کند، درحالی که در شکل سمت راست ابتدا $\theta_0$ تغییر می‌کند و بعد از آن در مرحله بعد برای محاسبه $\theta_1$ از مقدار جدید و تغییر داده شده $\theta_0$ استفاده می‌شود.
{{% /expand%}}